{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8835555,"sourceType":"datasetVersion","datasetId":5316968}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nimport os\n\n# Path to your zipped file\nzip_path = '/kaggle/input/assignment/FoodSeg103.zip'\n\n# Directory to extract files\nextract_dir = '/kaggle/working/'\n\n# Create directory if it doesn't exist\nos.makedirs(extract_dir, exist_ok=True)\n\n# Password for the zip file\npassword = b'LARCdataset9947'  # replace with your actual password\n\n# Unzipping the file\nwith zipfile.ZipFile(zip_path, 'r') as zip_ref:\n    zip_ref.extractall(extract_dir, pwd=password)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:04:41.688336Z","iopub.execute_input":"2024-07-02T16:04:41.688667Z","iopub.status.idle":"2024-07-02T16:47:15.633750Z","shell.execute_reply.started":"2024-07-02T16:04:41.688637Z","shell.execute_reply":"2024-07-02T16:47:15.632731Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install numpy pandas matplotlib scikit-learn tensorflow keras opencv-python\n!pip install opencv-python-headless tensorflow","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:47:15.635512Z","iopub.execute_input":"2024-07-02T16:47:15.635827Z","iopub.status.idle":"2024-07-02T16:47:43.761307Z","shell.execute_reply.started":"2024-07-02T16:47:15.635792Z","shell.execute_reply":"2024-07-02T16:47:43.760404Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.3.3)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.10.0.82)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.59.3)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nCollecting keras\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.3.3\n    Uninstalling keras-3.3.3:\n      Successfully uninstalled keras-3.3.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (4.10.0.82)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python-headless) (1.26.4)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.59.3)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Paths (replace with actual paths)\ndata_dir = '/kaggle/working/FoodSeg103'\nimage_train_dir = os.path.join(data_dir, 'Images/img_dir/train')\nmask_train_dir = os.path.join(data_dir, 'Images/ann_dir/train')\ntrain_list_file = os.path.join(data_dir, 'ImageSets/train.txt')\nimage_test_dir = os.path.join(data_dir, 'Images/img_dir/test')\nmask_test_dir = os.path.join(data_dir, 'Images/ann_dir/test')\ntest_list_file = os.path.join(data_dir, 'ImageSets/test.txt')\n\nprint(image_train_dir)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:47:43.762605Z","iopub.execute_input":"2024-07-02T16:47:43.762925Z","iopub.status.idle":"2024-07-02T16:47:55.859654Z","shell.execute_reply.started":"2024-07-02T16:47:43.762895Z","shell.execute_reply":"2024-07-02T16:47:55.858722Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-07-02 16:47:45.764032: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-02 16:47:45.764184: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-02 16:47:45.915525: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/working/FoodSeg103/Images/img_dir/train\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\n\n\n# Load image and mask paths\ndef load_image_mask_paths(file_path, image_dir, mask_dir):\n    with open(file_path, 'r') as file:\n        lines = file.readlines()\n    # Assuming train.txt lists filenames without extensions\n    image_paths = [os.path.join(image_dir, line.strip()) for line in lines]  # append .jpg\n    mask_paths = [os.path.join(mask_dir, line.strip()).replace('.jpg', '.png') for line in lines]   # append .png\n\n    # Debugging: print paths and check if files exist\n    for img_path, mask_path in zip(image_paths, mask_paths):\n        if not os.path.exists(img_path):\n            print(f\"Image file does not exist: {img_path}\")\n        if not os.path.exists(mask_path):\n            print(f\"Mask file does not exist: {mask_path}\")\n\n    return image_paths, mask_paths\n\n# Load training data\ntrain_image_paths, train_mask_paths = load_image_mask_paths(train_list_file, image_train_dir, mask_train_dir)\ntest_image_paths, test_mask_paths = load_image_mask_paths(test_list_file, image_test_dir, mask_test_dir)\n\n# Verify loaded paths\nprint(f\"Total images: {len(train_image_paths)}\")\nprint(f\"Total masks: {len(train_mask_paths)}\")\n\n# Example to load and check an image and its mask\nif len(train_image_paths) > 0:\n    print(f\"Example image path: {train_image_paths[0]}\")\n    print(f\"Example mask path: {train_mask_paths[0]}\")\nelse:\n    print(\"No training data loaded. Check paths and file extensions.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:47:55.862293Z","iopub.execute_input":"2024-07-02T16:47:55.863201Z","iopub.status.idle":"2024-07-02T16:47:55.973545Z","shell.execute_reply.started":"2024-07-02T16:47:55.863172Z","shell.execute_reply":"2024-07-02T16:47:55.972697Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Total images: 4983\nTotal masks: 4983\nExample image path: /kaggle/working/FoodSeg103/Images/img_dir/train/00000000.jpg\nExample mask path: /kaggle/working/FoodSeg103/Images/ann_dir/train/00000000.png\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# Load images and masks\ndef load_images_and_masks(image_paths, mask_paths, target_size=(256, 256)):\n    images = []\n    masks = []\n    for img_path, mask_path in zip(image_paths, mask_paths):\n        img = cv2.imread(img_path)\n        if img is None:\n            print(f\"Warning: Failed to load image at {img_path}\")\n            continue\n        img = cv2.resize(img, target_size)\n        img = img / 255.0  # Normalize to [0, 1]\n        images.append(img)\n\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        if mask is None:\n            print(f\"Warning: Failed to load mask at {mask_path}\")\n            continue\n        mask = cv2.resize(mask, target_size)\n        mask = mask / 255.0  # Normalize to [0, 1]\n        mask = np.expand_dims(mask, axis=-1)  # Add channel dimension for grayscale mask\n        masks.append(mask)\n    return np.array(images), np.array(masks)\n\n\n# Assuming train_image_paths, train_mask_paths, test_image_paths, and test_mask_paths are defined\ntrain_images, train_masks = load_images_and_masks(train_image_paths, train_mask_paths)\ntest_images, test_masks = load_images_and_masks(test_image_paths, test_mask_paths)\n\n# Ensure the arrays are not empty\nif train_images.size == 0 or train_masks.size == 0:\n    raise ValueError(\"No training data loaded. Please check your dataset paths and file extensions.\")\n\n# Data Augmentation parameters\ndata_gen_args = dict(rotation_range=15,\n                     width_shift_range=0.1,\n                     height_shift_range=0.1,\n                     shear_range=0.01,\n                     zoom_range=[0.9, 1.25],\n                     horizontal_flip=True,\n                     vertical_flip=True,\n                     fill_mode='reflect')\n\n# ImageDataGenerator for images and masks\nimage_datagen = ImageDataGenerator(**data_gen_args)\nmask_datagen = ImageDataGenerator(**data_gen_args)\n\n# Fit data generators\nseed = 1\nimage_datagen.fit(train_images, augment=True, seed=seed)\nmask_datagen.fit(train_masks, augment=True, seed=seed)\n\n# Create generators\ndef create_generators(image_datagen, mask_datagen, train_images, train_masks, batch_size=32):\n    image_generator = image_datagen.flow(train_images, batch_size=batch_size, seed=seed)\n    mask_generator = mask_datagen.flow(train_masks, batch_size=batch_size, seed=seed)\n    train_generator = zip(image_generator, mask_generator)\n    return train_generator\n\ntrain_generator = create_generators(image_datagen, mask_datagen, train_images, train_masks)\n\n# Example usage\nfor images, masks in train_generator:\n    print(images.shape, masks.shape)\n    break  # Break after the first batch for demonstration\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:47:55.974833Z","iopub.execute_input":"2024-07-02T16:47:55.975175Z","iopub.status.idle":"2024-07-02T16:50:49.689407Z","shell.execute_reply.started":"2024-07-02T16:47:55.975143Z","shell.execute_reply":"2024-07-02T16:50:49.688410Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(32, 256, 256, 3) (32, 256, 256, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip uninstall tensorflow\n# !pip install tensorflow\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:50:49.690582Z","iopub.execute_input":"2024-07-02T16:50:49.690872Z","iopub.status.idle":"2024-07-02T16:50:49.694795Z","shell.execute_reply.started":"2024-07-02T16:50:49.690848Z","shell.execute_reply":"2024-07-02T16:50:49.693824Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n\ndef unet(input_size=(256, 256, 3)):\n    inputs = Input(input_size)\n\n    # Encoder\n    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n\n    # Decoder\n    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=3)\n    conv6 = Conv2D(512, 3, activation='relu', padding='same')(up6)\n    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=3)\n    conv7 = Conv2D(256, 3, activation='relu', padding='same')(up7)\n    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=3)\n    conv8 = Conv2D(128, 3, activation='relu', padding='same')(up8)\n    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n\n    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=3)\n    conv9 = Conv2D(64, 3, activation='relu', padding='same')(up9)\n    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n\n    outputs = Conv2D(1, 1, activation='sigmoid')(conv9)\n\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:50:49.696135Z","iopub.execute_input":"2024-07-02T16:50:49.696816Z","iopub.status.idle":"2024-07-02T16:50:49.713737Z","shell.execute_reply.started":"2024-07-02T16:50:49.696782Z","shell.execute_reply":"2024-07-02T16:50:49.713025Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_generator = create_generators(image_datagen, mask_datagen, train_images, train_masks)\nvalidation_generator = create_generators(image_datagen, mask_datagen, test_images, test_masks)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:50:49.714708Z","iopub.execute_input":"2024-07-02T16:50:49.714980Z","iopub.status.idle":"2024-07-02T16:50:55.255802Z","shell.execute_reply.started":"2024-07-02T16:50:49.714958Z","shell.execute_reply":"2024-07-02T16:50:55.254533Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = unet()\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Assuming train_generator and validation_generator are defined\nmodel.fit(train_generator, validation_data=validation_generator, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:50:55.257041Z","iopub.execute_input":"2024-07-02T16:50:55.257340Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1719939091.515199     124 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"   5699/Unknown - 8809s 2s/step - loss: 0.3327 - accuracy: 0.4890","output_type":"stream"}]},{"cell_type":"code","source":"# Assuming create_generators function is defined as before\n\n# Create a validation data generator\nvalidation_generator = create_generators(image_datagen, mask_datagen, test_images, test_masks)\n\n# Example usage\nfor images, masks in validation_generator:\n    print(images.shape, masks.shape)\n    break\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet()\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.fit(train_generator, epochs=50, batch_size=16, validation_data=validation_generator)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}